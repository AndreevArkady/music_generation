{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sfBisbhQb6w"
      },
      "source": [
        "В этом ноутбуке буду тестировать различные алгоритмы и методы для выделения ключвых моментов в видео"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCFM8-kkkYR-"
      },
      "source": [
        "### 1. Тестирование модели R(2+1)D из статьи \"Large-scale weakly-supervised pre-training for video action recognition\" (2019)\n",
        "\n",
        "(convolutional neural network is a network for action recognition that employs R(2+1)D convolutions in a ResNet inspired architecture)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFY2rirFPdFc",
        "outputId": "3c1aeafb-9c4e-4d84-efd7-4fc23b5552e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'computervision-recipes' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/microsoft/computervision-recipes.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGxksyjRSEqZ",
        "outputId": "c47e2630-03ef-4419-ae11-7e73c397419e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from decord) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install decord"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TARXONaeSoX7",
        "outputId": "b5a3becb-2752-4a1f-861d-c572a882d257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "p000DTFZ3WS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XlugJ-4RfnZ"
      },
      "outputs": [],
      "source": [
        "# Regular Python libraries\n",
        "import sys\n",
        "from collections import deque #\n",
        "import io\n",
        "import requests\n",
        "import os\n",
        "from time import sleep, time\n",
        "from threading import Thread\n",
        "from IPython.display import Video\n",
        "\n",
        "# Third party tools\n",
        "import decord #\n",
        "import IPython.display #\n",
        "# from ipywebrtc import CameraStream, ImageRecorder\n",
        "from ipywidgets import HBox, HTML, Layout, VBox, Widget, Label\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.cuda as cuda\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import Compose\n",
        "\n",
        "# utils_cv\n",
        "sys.path.append(\"/content/computervision-recipes\")\n",
        "from utils_cv.action_recognition.data import KINETICS, Urls\n",
        "from utils_cv.action_recognition.dataset import get_transforms\n",
        "from utils_cv.action_recognition.model import VideoLearner\n",
        "from utils_cv.action_recognition.references import transforms_video as transforms\n",
        "from utils_cv.common.gpu import system_info, torch_device\n",
        "from utils_cv.common.data import data_path\n",
        "\n",
        "# system_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "extGDmi6vrxl",
        "outputId": "eff33b3d-3684-4b4e-b281-9e02769be0e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.11 (main, Apr  5 2023, 14:15:10) [GCC 9.4.0] \n",
            "\n",
            "PyTorch 2.0.0+cu118 \n",
            "\n",
            "Torch-vision 0.15.1+cu118 \n",
            "\n",
            "Available devices:\n",
            "0: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "system_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WFlPo1BR7ge"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKit-8HWVD-l"
      },
      "outputs": [],
      "source": [
        "!mv /content/video_ad8.mp4 /content/computervision-recipes/data/video_ad8.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nsbcbhs1TFVk"
      },
      "outputs": [],
      "source": [
        "NUM_FRAMES = 8  # 8 or 32.\n",
        "IM_SCALE = 128  # resize then crop\n",
        "INPUT_SIZE = 112  # input clip size: 3 x NUM_FRAMES x 112 x 112\n",
        "\n",
        "# video sample to download\n",
        "# sample_video_url = Urls.webcam_vid\n",
        "# sample_video_url = '/content/computervision-recipes/data/video_ad12.mp4'\n",
        "# file path to save video sample\n",
        "# video_fpath = data_path() / \"sample_video.mp4\"\n",
        "# video_fpath = data_path() / \"video_ad12.mp4\"\n",
        "\n",
        "# prediction score threshold\n",
        "SCORE_THRESHOLD = 0.1\n",
        "\n",
        "# Averaging 5 latest clips to make video-level prediction (or smoothing)\n",
        "AVERAGING_SIZE = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcvw4-5-TQmD",
        "outputId": "12b3f78b-a142-4730-b52d-cc75311bece1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading r2plus1d_34_8_kinetics model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/hub.py:286: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/moabitcoin/ig65m-pytorch/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://github.com/moabitcoin/ig65m-pytorch/releases/download/v1.0.0/r2plus1d_34_clip8_ft_kinetics_from_ig65m-0aa0550b.pth\" to /root/.cache/torch/hub/checkpoints/r2plus1d_34_clip8_ft_kinetics_from_ig65m-0aa0550b.pth\n"
          ]
        }
      ],
      "source": [
        "# Load R(2+1)D 34-layer model pre-trained Kinetics400\n",
        "learner = VideoLearner(\n",
        "    base_model=\"kinetics\",\n",
        "    sample_length=NUM_FRAMES,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW9BiHGSTamB",
        "outputId": "3d047f18-17cd-48e1-9887-2217975c700e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abseiling',\n",
              " 'air drumming',\n",
              " 'answering questions',\n",
              " 'applauding',\n",
              " 'applying cream',\n",
              " 'archery',\n",
              " 'arm wrestling',\n",
              " 'arranging flowers',\n",
              " 'assembling computer',\n",
              " 'auctioning']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "LABELS = KINETICS.class_names\n",
        "LABELS[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5qVXh1dTl9R"
      },
      "outputs": [],
      "source": [
        "# Video(sample_video_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_CgfygJTn_g"
      },
      "outputs": [],
      "source": [
        "# r = requests.get(sample_video_url)\n",
        "# open(video_fpath, 'wb').write(r.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_-UvpBQ0TwA7"
      },
      "outputs": [],
      "source": [
        "# video = str(data_path()/\"video_ad12.mp4\")\n",
        "video = '/content/video_ad8.mp4'\n",
        "learner.predict_video(\n",
        "    video,\n",
        "    LABELS,\n",
        "    averaging_size=1,\n",
        "    score_threshold=SCORE_THRESHOLD,\n",
        "    # target_labels=TARGET_LABELS,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "jXKyBiXKTzV7",
        "outputId": "f0ea9a5f-44bf-45fa-b460-b8b807e14564"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'Preparing...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : Секунда:  1.6666666666666667 , началось действие:  smoking\n",
            "2 : Секунда:  3.3333333333333335 , началось действие:  driving car\n",
            "3 : Секунда:  5.0 , началось действие:  texting\n",
            "4 : Секунда:  6.666666666666667 , началось действие:  barbequing\n",
            "5 : Секунда:  11.666666666666666 , началось действие:  running on treadmill\n",
            "6 : Секунда:  13.333333333333334 , началось действие:  eating burger\n",
            "7 : Секунда:  15.0 , началось действие:  kissing\n",
            "8 : Секунда:  16.666666666666668 , началось действие:  texting\n",
            "9 : Секунда:  21.666666666666668 , началось действие:  driving car\n",
            "10 : Секунда:  23.333333333333332 , началось действие:  tasting food\n",
            "11 : Секунда:  25.0 , началось действие:  chopping wood\n",
            "12 : Секунда:  26.666666666666668 , началось действие:  country line dancing\n",
            "13 : Секунда:  28.333333333333332 , началось действие:  singing\n",
            "14 : Секунда:  30.0 , началось действие:  dining\n",
            "15 : Секунда:  33.333333333333336 , началось действие:  giving or receiving award\n",
            "16 : Секунда:  35.0 , началось действие:  eating burger\n",
            "17 : Секунда:  36.666666666666664 , началось действие:  news anchoring\n"
          ]
        }
      ],
      "source": [
        "video = '/content/video_ad8.mp4'\n",
        "LABELS = KINETICS.class_names\n",
        "\n",
        "transforms = get_transforms(train=False)\n",
        "d_caption = IPython.display.display(\"Preparing...\", display_id=2)\n",
        "l = len(LABELS)\n",
        "def update_println(println):\n",
        "  d_caption.update(IPython.display.HTML(println))\n",
        "\n",
        "video_reader = decord.VideoReader(video)\n",
        "window = deque()\n",
        "scores_cache = deque()\n",
        "scores_sum = np.zeros(len(LABELS))\n",
        "w_text = HTML(layout=Layout(padding=\"0 0 0 100px\"))\n",
        "\n",
        "cur_frame = 0\n",
        "num = 1\n",
        "prev_name = ''\n",
        "key_video_moments = {}\n",
        "while True:\n",
        "  try:\n",
        "    frame = video_reader.next().asnumpy()\n",
        "    window.append(frame)\n",
        "    def update_println(println):\n",
        "        w_text.value = println\n",
        "\n",
        "    if len(window) == NUM_FRAMES:\n",
        "        a = learner.predict_frames(\n",
        "            window,\n",
        "            scores_cache,\n",
        "            scores_sum,\n",
        "            None,\n",
        "            30,\n",
        "            SCORE_THRESHOLD,\n",
        "            LABELS,\n",
        "            LABELS,\n",
        "            get_transforms(train=False),\n",
        "            update_println,\n",
        "        )\n",
        "        if cur_frame == 0:\n",
        "          prev_name = a\n",
        "          key_video_moments[num] = cur_frame/30\n",
        "          print(num, ': Секунда: ', cur_frame/30, ', началось действие: ', prev_name)\n",
        "          num += 1\n",
        "        elif cur_frame%50==0 and a != '' and prev_name != a:\n",
        "          prev_name = a\n",
        "          key_video_moments[num] = cur_frame/30\n",
        "          print(num, ': Секунда: ', cur_frame/30, ', началось действие: ', prev_name)\n",
        "          num += 1\n",
        "        # print(a)\n",
        "    else:\n",
        "        w_text.value = \"Preparing...\"\n",
        "    cur_frame += 1\n",
        "    # print(cur_frame)\n",
        "  except:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lR9lC28lVE3"
      },
      "outputs": [],
      "source": [
        "# Дополнения в коде /content/computervision-recipes/utils_cv/action_recognition/model.py в predict_frames\n",
        "# top5 = None\n",
        "# ...\n",
        "# return top5[0][0] if top5 and len(top5) else ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBSiWXto18SI"
      },
      "source": [
        "### Key Frame Detector (https://github.com/joelibaceta/video-keyframe-detector)\n",
        "\n",
        "(основан на методах из opencv, а именно на пиксельной разнице между кадрами)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1BevWyG2FwZ",
        "outputId": "396a3b21-5463-4b30-c8ac-4531168ed690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'video-keyframe-detector'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 98 (delta 0), reused 0 (delta 0), pack-reused 95\u001b[K\n",
            "Unpacking objects: 100% (98/98), 7.66 MiB | 15.72 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/joelibaceta/video-keyframe-detector.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lccHAf3XfAGr",
        "outputId": "8a4862cf-a800-44b8-f793-86292019dc0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/video-keyframe-detector\n"
          ]
        }
      ],
      "source": [
        "%cd /content/video-keyframe-detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-tu3k4eeudE"
      },
      "outputs": [],
      "source": [
        "!pip install -v -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6oztB4xMg19",
        "outputId": "ae7323e6-ffcb-4b7c-b590-b195fefa84d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/res/keyFrames': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm -rv /content/res/keyFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwzS6tIBewry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c3c7e2-5125-4f33-f5f6-155bb3a1441a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "keyframe 2 happened at 1.5666666666666667 sec.\n",
            "keyframe 3 happened at 4.333333333333333 sec.\n",
            "keyframe 4 happened at 6.966666666666667 sec.\n",
            "keyframe 5 happened at 8.7 sec.\n",
            "keyframe 6 happened at 10.166666666666666 sec.\n",
            "keyframe 7 happened at 10.466666666666667 sec.\n",
            "keyframe 8 happened at 11.0 sec.\n",
            "keyframe 9 happened at 13.966666666666667 sec.\n",
            "keyframe 10 happened at 15.133333333333333 sec.\n",
            "keyframe 11 happened at 21.8 sec.\n",
            "keyframe 12 happened at 22.566666666666666 sec.\n",
            "keyframe 13 happened at 24.7 sec.\n",
            "keyframe 14 happened at 26.0 sec.\n",
            "keyframe 15 happened at 30.8 sec.\n",
            "keyframe 16 happened at 32.9 sec.\n",
            "keyframe 17 happened at 34.93333333333333 sec.\n"
          ]
        }
      ],
      "source": [
        "!python cli.py -s /content/video_ad8.mp4 -d /content/res  -t 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exY-eb_YfUG8"
      },
      "outputs": [],
      "source": [
        "# !ls -l /content/res/imageGrids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3_iqBRsgQzh"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# df = pd.read_csv('/content/res/csvFile/output.csv', sep=' ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Amb8YVIagZP7"
      },
      "outputs": [],
      "source": [
        "# Дополнение к коду: заменить на timeSpans.append(i/30) и verbose=True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoYqd4jlNxvn"
      },
      "source": [
        "### Что еще можно попробовать:\n",
        "- https://github.com/facebookresearch/detectron2/blob/main/projects/DensePose/densepose/data/video/video_keyframe_dataset.py\n",
        "\n",
        "- https://mmaction2.readthedocs.io/en/latest/localization_models.html\n",
        "\n",
        "- https://github.com/happyharrycn/actionformer_release\n",
        "\n",
        "- https://github.com/klauscc/TALLFormer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I563-35JaLXy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}